# Markov Chain 

> A Markov chain or Markov process is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. A countably infinite sequence, in which the chain moves state at discrete time steps, gives a discrete-time Markov chain

## how to use
import model into jupyter notebook, follow notes & replace w/ own text

example text used is In Praise of Shadows
